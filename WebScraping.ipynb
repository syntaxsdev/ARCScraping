{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is for testing the WebScraping class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, random, Universities\n",
    "from urllib.parse import urlparse\n",
    "from UserAgents import UserAgents\n",
    "from User import User\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class WebScraping:\n",
    "    bs4 = None\n",
    "    def __init__(self):\n",
    "        self.linkFilterPrefixes = [\"/search\", \"q=\", \"/?\", \"/advanced_search\"]\n",
    "        self.linkFilterSearches = [\"google\", \"facebook\", \"instagram\", \"linkedin\", \"twitter\", \"ratemyprofessors\"]\n",
    "        bs4 = BeautifulSoup()\n",
    "\n",
    "    '''\n",
    "    The initial search perform a google search on the user using the query \"{FIRST LAST} {INSTITUTION}\"\n",
    "    and returns all the links\n",
    "    '''\n",
    "    def initial_search(self, user: User):\n",
    "        user_name = \"+\".join(user.name) + f\" {user.institution}\"\n",
    "\n",
    "        # Tweaks should be done here, maybe make a link scraper by itself\n",
    "\n",
    "        #search_url = f\"https://www.google.com/search?q=%22{user_name}%22\"\n",
    "        search_url = f\"https://www.google.com/search?q={user_name}\"\n",
    "\n",
    "        # End of tweaks\n",
    "        req = self.request(search_url)\n",
    "        bs = BeautifulSoup(req.content, 'html.parser')\n",
    "\n",
    "        # Select every single <a> element\n",
    "        raw_links = bs.select(\"a\")\n",
    "        # Filter links that do not contain \"google.com\" or start with the prefixes defined.\n",
    "        links = [link['href'] for link in raw_links if not any(link['href'].startswith(prefix) \n",
    "                    or link['href'].find('google.com') > 0 for prefix in self.linkFilterPrefixes)] \n",
    "        \n",
    "        # Filter links that don't contain searches\n",
    "        links = [link for link in links if not any(link.find(search) > -1 for search in self.linkFilterSearches)]\n",
    "\n",
    "        # Only grab the relevent part of the link if it includes more in it\n",
    "        links = [link.split(\"/url?q=\")[-1].split(\"&sa\")[0] for link in links]\n",
    "        user.initial_search_links = links\n",
    "        return links\n",
    "    \n",
    "    '''\n",
    "    Verify if the link is relevent to the researcher. 2/3 is required to be used.\n",
    "    1. First checks if the institution can be found on the page text.\n",
    "    2. Checks if the researchers name can be found on the page check.\n",
    "    3. Check if the URL is from their institution.\n",
    "    '''\n",
    "    def verify_link_relevancy(self, link: str, page_data: str, user: User):\n",
    "        page_data = page_data.lower()\n",
    "        user_name = \"+\".join(user.name).lower()\n",
    "        checks = 0\n",
    "        reason = \"\"\n",
    "\n",
    "        # Check 1\n",
    "        if page_data.find(user.institution.lower()):\n",
    "            checks += 1\n",
    "            reason += \"Instituion found | \"\n",
    "\n",
    "        # Check 2\n",
    "        if page_data.find(user_name):\n",
    "            checks += 1\n",
    "            reason += \"Researcher name found | \"\n",
    "        \n",
    "        # Check 3\n",
    "        if Universities.findUniversityLink(user.institution).find(link) > -1:\n",
    "            checks += 1\n",
    "            reason += \"University website verified\"\n",
    "        return (checks >= 2, checks, reason)\n",
    "        \n",
    "    ''' \n",
    "    Scrape the webpage and get the webtext without HTML tags\n",
    "    then check verify the source is reputable by a 3 part check method\n",
    "    '''\n",
    "    def scrape_webpage(self, link: str, user: User):\n",
    "        # Request the page and convert to BS4\n",
    "        req = self.request(link)\n",
    "        bs = BeautifulSoup(req.content, 'html.parser')\n",
    "        \n",
    "        # Grab only the webtext (text without HTML tags)\n",
    "        webtext = bs.get_text().replace('\\n', '').strip()\n",
    "        \n",
    "        # Parse the URL so that we can only get the base domain\n",
    "        parsed_url = urlparse(link)\n",
    "        domain_parts = parsed_url.netloc.split('.')\n",
    "        domain = '.'.join(domain_parts[-2:])\n",
    "\n",
    "        # Do a 3 part check on the domain, webtext, and the user to verify it pertains to the user\n",
    "        verified, check, reason = self.verify_link_relevancy(domain, webtext, user)\n",
    "\n",
    "        # <TODO>\n",
    "        #NOT DONE\n",
    "        print(verified, check, reason)\n",
    "        print(webtext)\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    Internal request method that faciliates parameters and headers\n",
    "    :return: `Response`\n",
    "    '''\n",
    "    def request(self, link) -> requests.Response:\n",
    "        return requests.get(link, self.genHeaders())\n",
    "\n",
    "    '''\n",
    "    Generate new headers\n",
    "    '''\n",
    "    def genHeaders(self) -> dict:\n",
    "        return {\n",
    "        'User-agent': self.getRandAgent()\n",
    "        }\n",
    "\n",
    "    ''' \n",
    "    Returns a random UserAgent for the headers\n",
    "    '''\n",
    "    def getRandAgent(self) -> str:\n",
    "        return UserAgents[random.randrange(len(UserAgents))]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Test with researcher Zheng Xiang from VT</b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 2 Instituion found | Researcher name found | \n",
      "Zheng Xiang - Editorial Board - Tourism Management - Journal - ElsevierSkip to contentSign in to view your account details and order historySign inAbout ElsevierAbout usElsevier ConnectCareersAbout ElsevierAbout usElsevier ConnectCareersProducts & SolutionsR & D SolutionsClinical SolutionsResearch PlatformsResearch IntelligenceEducationAll SolutionsProducts & SolutionsR & D SolutionsClinical SolutionsResearch PlatformsResearch IntelligenceEducationAll SolutionsServicesAuthorsEditorsReviewersLibrariansStrategic PartnersOpen AccessSocietiesServicesAuthorsEditorsReviewersLibrariansStrategic PartnersOpen AccessSocietiesShop & DiscoverBooks & JournalsAuthor Webshop Shop & DiscoverBooks & JournalsAuthor Webshop SearchSearch by keyword, title, subject areaTourism ManagementImpact Factor12.879CiteScore19.8View articlesSubmit your paperHomeJournalsTourism ManagementEditorial Board Zheng XiangISSN: 0261-5177Tourism ManagementSubmit your PaperView ArticlesGuide for authorsTrack your paperCheck submitted paperTrack accepted paperOrder journalInstitutional subscriptionPersonal subscriptionSample issue Zheng XiangInternational Editorial BoardVirginia Tech University, Department of Hospitality and Tourism Management, Blacksburg, Virginia, United States of AmericaZheng Xiang is an Associate Professor in the Howard Feiertag Department of Hospitality and Tourism Management in the Pamplin College of Business at Virginia Tech. His research focuses on the strategic implications of information technologies for the hospitality and tourism industry. He currently serves as President of the International Federation for IT and Travel & Tourism (IFITT) and Editor-in-Chief of the Journal of Information Technology & Tourism. He has published more than 90 peer-reviewed journal articles, conference papers, and book chapters. He has co-authored one textbook Tourism Information Technology (3rd edition) and co-edited two books related data analytics in hospitality and tourism management.A number of Xiang’s co-authored articles have received Best Paper award in international journals and conferences. In May 2015, he received the “Emerging Scholar of Distinction” award from the International Academy for the Study of Tourism. Recently, he was designated by the Web of Science Group as a “Highly Cited Researcher 2019” (top 1% among researchers around the world) based upon citations to his work in the last decade. Xiang holds a Ph.D. in Business Administration from Temple University and a Master of Science degree in Leisure Studies from University of Illinois at Urbana-Champaign. Tourism ManagementReadersView ArticlesSample IssueVolume/Issue AlertPersonalized RecommendationsAuthorsSubmit your PaperCheck Submitted PaperResearcher AcademyRights and PermissionsElsevier Author ServicesSupport CenterTrack Accepted PaperLibrariansOrder Journal PersonalOrder Journal InstitutionalEditorsPublishing Ethics Resource KitSupport CenterReviewersReviewer GuidelinesLog in as ReviewerReviewer RecognitionSupport CenterCopyright © 2023 Elsevier, except certain content provided by third partiesCookies are used by this site. Cookie SettingsTerms and ConditionsPrivacy PolicyCookie NoticeSitemap\n"
     ]
    }
   ],
   "source": [
    "ws = WebScraping()\n",
    "zheng = User(\"Zheng Xiang\", \"Virginia Tech\")\n",
    "ws.initial_search(zheng)\n",
    "zheng.initial_search_links\n",
    "\n",
    "ws.scrape_webpage(zheng.initial_search_links[3], zheng)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://htm.pamplin.vt.edu/directory/xiang.html',\n",
       " 'https://www.researchgate.net/profile/Zheng-Xiang-6',\n",
       " 'https://www.researchgate.net/scientific-contributions/Zheng-Xiang-2164885495',\n",
       " 'https://www.journals.elsevier.com/tourism-management/editorial-board/zheng-xiang',\n",
       " 'https://www.youtube.com/watch%3Fv%3DFtoSQPBzjao',\n",
       " 'https://www.youtube.com/watch%3Fv%3DFtoSQPBzjao',\n",
       " 'https://us.sagepub.com/en-us/nam/author/zheng-xiang']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zheng.initial_search_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/cordero/Documents/Capstone/WebScrape/ARCScraping/WebScraping.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cordero/Documents/Capstone/WebScrape/ARCScraping/WebScraping.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m links \u001b[39m=\u001b[39m bs\u001b[39m.\u001b[39mselect(\u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cordero/Documents/Capstone/WebScrape/ARCScraping/WebScraping.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m prefixes \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m/search\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mq=\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m/?\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m/advanced_search\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cordero/Documents/Capstone/WebScrape/ARCScraping/WebScraping.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m links \u001b[39m=\u001b[39m [link[\u001b[39m'\u001b[39m\u001b[39mhref\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m link \u001b[39min\u001b[39;00m links \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(link[\u001b[39m'\u001b[39m\u001b[39mhref\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstartswith(prefix) \u001b[39mor\u001b[39;00m link[\u001b[39m'\u001b[39m\u001b[39mhref\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mgoogle.com\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m prefix \u001b[39min\u001b[39;00m prefixes)] \n",
      "\u001b[0;31mNameError\u001b[0m: name 'bs' is not defined"
     ]
    }
   ],
   "source": [
    "links = bs.select(\"a\")\n",
    "prefixes = [\"/search\", \"q=\", \"/?\", \"/advanced_search\"]\n",
    "links = [link['href'] for link in links if not any(link['href'].startswith(prefix) or link['href'].find('google.com') > 0 for prefix in prefixes)] \n",
    "links = [link.split(\"/url?q=\")[-1] for link in links]\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0afb4cd576355fff8ce021c87ea1746aa4b89951b59e2653bef89f9056735253"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
